<!DOCTYPE html>
<html lang="es">

<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>IAVisionPay</title>
  <style>
    * {
      box-sizing: border-box;
    }

    body {
      font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
      background: #f5f5f5;
      margin: 0;
      padding: 20px;
      display: flex;
      flex-direction: column;
      align-items: center;
    }

    h2 {
      color: #333;
      margin-bottom: 20px;
      text-align: center;
    }

    video {
      border: 4px solid #4CAF50;
      border-radius: 10px;
      box-shadow: 0 4px 12px rgba(0, 0, 0, 0.2);
      width: 100%;
      max-width: 640px;
      height: auto;
    }

    button {
      margin-top: 10px;
      background-color: #4CAF50;
      color: white;
      padding: 12px 24px;
      font-size: 16px;
      border: none;
      border-radius: 8px;
      cursor: pointer;
      transition: background-color 0.3s ease;
      width: 100%;
      max-width: 300px;
    }

    button.stop {
      background-color: #f44336;
    }

    button:hover {
      opacity: 0.9;
    }

    #resultado {
      margin-top: 20px;
      font-size: 20px;
      color: #222;
      background: #e0f7e9;
      padding: 10px 20px;
      border-radius: 6px;
      box-shadow: 0 2px 6px rgba(0, 0, 0, 0.1);
      text-align: center;
      width: 100%;
      max-width: 300px;
    }

    .slider-container {
      margin-top: 20px;
      text-align: center;
      width: 100%;
      max-width: 300px;
    }

    input[type=range] {
      width: 100%;
    }

    .volume-label {
      margin-bottom: 5px;
      color: #555;
    }

    @media (max-width: 480px) {
      h2 {
        font-size: 18px;
      }

      button {
        font-size: 14px;
        padding: 10px;
      }

      #resultado {
        font-size: 16px;
      }
    }
  </style>
</head>

<body>
  <h2>Reconocimiento de objetos</h2>
  <video id="video" autoplay playsinline></video>

  <div class="slider-container">
    <div class="volume-label">Volumen de voz: <span id="volumeValue">100</span>%</div>
    <input type="range" min="0" max="100" value="100" id="volumeSlider" />
  </div>

  <button id="startBtn" onclick="startCapture()">Iniciar captura autom√°tica</button>
  <button id="stopBtn" class="stop" onclick="stopCapture()" style="display: none;">Detener captura</button>

  <p id="resultado"></p>

  <script>
    const video = document.getElementById('video');
    const resultado = document.getElementById('resultado');
    const volumeSlider = document.getElementById('volumeSlider');
    const volumeValue = document.getElementById('volumeValue');
    const startBtn = document.getElementById('startBtn');
    const stopBtn = document.getElementById('stopBtn');

    let voiceVolume = 1.0;
    let capturing = false;
    let availableVoices = [];

    speechSynthesis.onvoiceschanged = () => {
      availableVoices = speechSynthesis.getVoices();
    };

    volumeSlider.addEventListener('input', () => {
      voiceVolume = volumeSlider.value / 100;
      volumeValue.textContent = volumeSlider.value;
    });

    navigator.mediaDevices.getUserMedia({ video: true })
      .then(stream => {
        video.srcObject = stream;
      })
      .catch(err => {
        resultado.textContent = "‚ùå Error al acceder a la c√°mara: " + err.message;
      });

    async function capture() {
      if (!capturing) return;

      const canvas = document.createElement("canvas");
      canvas.width = 224;
      canvas.height = 224;
      const ctx = canvas.getContext("2d");
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

      const dataURL = canvas.toDataURL("image/jpeg");
      const base64Image = dataURL.split(',')[1];

      try {
        const response = await fetch("/predict", {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ image: base64Image })
        });

        const result = await response.json();

        if (result.label && result.confidence >= 0.9) {
          resultado.textContent = `${result.label} (${(result.confidence * 100).toFixed(1)}%)`;

          const msg = new SpeechSynthesisUtterance(result.label);
          msg.volume = voiceVolume;
          msg.pitch = 1.1;
          msg.rate = 0.95;
          msg.lang = result.language === "es" ? "es-ES"
            : result.language === "pt" ? "pt-BR"
              : "en-US";

          const preferredVoice = availableVoices.find(v => v.lang === msg.lang);
          if (preferredVoice) {
            msg.voice = preferredVoice;
          }

          msg.onend = () => {
            if (capturing) setTimeout(capture, 500);
          };

          speechSynthesis.cancel();
          speechSynthesis.speak(msg);
        } else if (result.label) {
          resultado.textContent = `ü§î Pensando...`;
          setTimeout(capture, 1000);
        } else {
          resultado.textContent = "‚ö†Ô∏è Error: " + JSON.stringify(result);
          setTimeout(capture, 1500);
        }


      } catch (err) {
        resultado.textContent = "‚ùå Error al enviar la imagen: " + err;
        setTimeout(capture, 1500);
      }
    }

    function startCapture() {
      if (!capturing) {
        capturing = true;
        startBtn.style.display = "none";
        stopBtn.style.display = "inline-block";
        capture();
      }
    }

    function stopCapture() {
      capturing = false;
      speechSynthesis.cancel();
      startBtn.style.display = "inline-block";
      stopBtn.style.display = "none";
      resultado.textContent = "Captura detenida";
    }
  </script>
</body>

</html>